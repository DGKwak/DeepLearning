{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import re\n",
    "import json\n",
    "from konlpy.tag import Okt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "DATA_IN_PATH = './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Crawl_Data = pd.read_csv('data/KakaoBank_Reveiw_Crawl.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3800 entries, 0 to 3799\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  3800 non-null   int64 \n",
      " 1   id          3800 non-null   int64 \n",
      " 2   date        3800 non-null   int64 \n",
      " 3   dateYear    3800 non-null   int64 \n",
      " 4   dateMonth   3800 non-null   int64 \n",
      " 5   dateDay     3800 non-null   int64 \n",
      " 6   rating      3800 non-null   int64 \n",
      " 7   userName    3800 non-null   object\n",
      " 8   content     3800 non-null   object\n",
      "dtypes: int64(7), object(2)\n",
      "memory usage: 267.3+ KB\n"
     ]
    }
   ],
   "source": [
    "Crawl_Data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "중복값 확인 및 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3746"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Crawl_Data['content'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Crawl_Data.drop_duplicates(subset=['content'], inplace=True)\n",
    "\n",
    "Crawl_Data.drop(['Unnamed: 0', 'id', 'date', 'userName'], axis=1, inplace=True)\n",
    "\n",
    "Test_Data = Crawl_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(review, okt, remove_stopwords = False, stop_words = []):\n",
    "    # 함수의 인자는 다음과 같다.\n",
    "    # review : 전처리할 텍스트\n",
    "    # okt : okt 객체를 반복적으로 생성하지 않고 미리 생성후 인자로 받는다.\n",
    "    # remove_stopword : 불용어를 제거할지 선택 기본값은 False\n",
    "    # stop_word : 불용어 사전은 사용자가 직접 입력해야함 기본값은 비어있는 리스트\n",
    "    \n",
    "    # 1. 한글 및 공백을 제외한 문자 모두 제거.\n",
    "    review_text = re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]\", \"\", review)\n",
    "    \n",
    "    # 2. okt 객체를 활용해서 형태소 단위로 나눈다.\n",
    "    word_review = okt.morphs(review_text, stem=True)\n",
    "    \n",
    "    if remove_stopwords:\n",
    "        \n",
    "        # 불용어 제거(선택적)\n",
    "        word_review = [token for token in word_review if not token in stop_words]\n",
    "        \n",
    "   \n",
    "    return word_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt=Okt()\n",
    "processed_data=[]\n",
    "\n",
    "test_data = []\n",
    "\n",
    "for review in Crawl_Data['content']:\n",
    "    processed_data.append(preprocessing(review, okt, remove_stopwords=True, stop_words=[]))\n",
    "    \n",
    "for review in Test_Data['content']:\n",
    "    test_data.append(preprocessing(review, okt, remove_stopwords=True, stop_words=[]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(processed_data)\n",
    "Train_sequences=tokenizer.texts_to_sequences(processed_data)\n",
    "Test_sequences=tokenizer.texts_to_sequences(test_data)\n",
    "\n",
    "# 단어 사전 형태\n",
    "word_vocab=tokenizer.word_index\n",
    "\n",
    "# 문장 최대 길이\n",
    "MAX_SEQUENCE_LENGTH=8\n",
    "\n",
    "# 학습 데이터를 벡터화\n",
    "Train_inputs=pad_sequences(Train_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "# 학습 데이터의 라벨\n",
    "Train_labels=np.array([Crawl_Data['rating']])\n",
    "\n",
    "# 평가 데이터를 벡터화\n",
    "Test_inputs=pad_sequences(Test_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "# 평가 데이터의 라벨\n",
    "Test_labels=np.array([Test_Data['rating']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_i = pd.DataFrame(Train_inputs)\n",
    "Train_l = pd.DataFrame(Train_labels)\n",
    "Test_i = pd.DataFrame(Test_inputs)\n",
    "Test_l = pd.DataFrame(Test_labels)\n",
    "\n",
    "Train_i.to_csv('./data/Train_inputs.csv', encoding='utf-8')\n",
    "Train_l.to_csv('./data/Train_labels.csv', encoding='utf-8')\n",
    "Test_i.to_csv('./data/Test_inputs.csv', encoding='utf-8')\n",
    "Test_l.to_csv('./data/Test_labels.csv', encoding='utf-8')\n",
    "\n",
    "data_configs = {}\n",
    "\n",
    "data_configs['vocab_size'] = word_vocab\n",
    "\n",
    "# 데이터 사전을 json 형태로 저장\n",
    "json.dump(data_configs, open(DATA_IN_PATH+'data_configs.json','w'), ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f6e3b18aee0be1d8bbda429ec202ef0084c30d3267feb3deeb863225f680e76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
